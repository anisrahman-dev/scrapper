name: Fetch latest news

on:
  schedule:
    - cron: "*/30 * * * *"
  workflow_dispatch:

permissions:
  contents: write

jobs:
  fetch:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Fetch news from Prothom Alo categories
        run: |
          python - <<'PY'
          import json
          import urllib.request
          from html.parser import HTMLParser
          from datetime import datetime, timezone
          from urllib.parse import urljoin

          CATEGORIES = {
              "bangladesh": "https://www.prothomalo.com/bangladesh",
              "politics": "https://www.prothomalo.com/politics",
              "world": "https://www.prothomalo.com/world",
              "business": "https://www.prothomalo.com/business",
              "sports": "https://www.prothomalo.com/sports",
              "entertainment": "https://www.prothomalo.com/entertainment",
              "chakri": "https://www.prothomalo.com/chakri",
          }

          HEADERS = {
              "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)",
          }

          class NewsParser(HTMLParser):
              def __init__(self):
                  super().__init__()
                  self.items = []
                  self.in_a = False
                  self.current_link = None

              def handle_starttag(self, tag, attrs):
                  attrs = dict(attrs)
                  if tag == "a" and "href" in attrs and attrs["href"].startswith("/"):
                      self.in_a = True
                      self.current_link = attrs["href"]

              def handle_data(self, data):
                  if self.in_a:
                      text = data.strip()
                      if len(text) > 25:
                          self.items.append({
                              "headline": text,
                              "url": urljoin("https://www.prothomalo.com", self.current_link)
                          })

              def handle_endtag(self, tag):
                  if tag == "a":
                      self.in_a = False
                      self.current_link = None

          output = {
              "fetched_at": datetime.now(timezone.utc).isoformat(),
              "categories": {}
          }

          for name, url in CATEGORIES.items():
              req = urllib.request.Request(url, headers=HEADERS)
              with urllib.request.urlopen(req, timeout=20) as resp:
                  html = resp.read().decode("utf-8", errors="ignore")

              parser = NewsParser()
              parser.feed(html)

              # Deduplicate
              seen = set()
              stories = []
              for item in parser.items:
                  if item["url"] not in seen:
                      seen.add(item["url"])
                      stories.append(item)

              output["categories"][name] = stories[:20]

          with open("latest_news.json", "w", encoding="utf-8") as f:
              json.dump(output, f, ensure_ascii=False, indent=2)

          print("Fetched categories:", ", ".join(output["categories"].keys()))
          PY

      - name: Commit and push changes
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git add latest_news.json
          if git diff --cached --quiet; then
            echo "No changes to commit."
            exit 0
          fi
          git commit -m "chore: update category news"
          git push
