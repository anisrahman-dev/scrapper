      - name: Fetch news from Prothom Alo categories
        run: |
          python - <<'PY'
          import json
          import urllib.request
          import re
          from datetime import datetime, timezone

          CATEGORIES = {
              "bangladesh": "https://www.prothomalo.com/bangladesh",
              "politics": "https://www.prothomalo.com/politics",
              "world": "https://www.prothomalo.com/world",
              "business": "https://www.prothomalo.com/business",
              "sports": "https://www.prothomalo.com/sports",
              "entertainment": "https://www.prothomalo.com/entertainment",
              "chakri": "https://www.prothomalo.com/chakri",
          }

          HEADERS = {
              "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"
          }

          def fetch_page(url):
              req = urllib.request.Request(url, headers=HEADERS)
              with urllib.request.urlopen(req, timeout=20) as r:
                  return r.read().decode("utf-8", errors="ignore")

          output = {
              "fetched_at": datetime.now(timezone.utc).isoformat(),
              "categories": {}
          }

          for cat, url in CATEGORIES.items():
              html = fetch_page(url)

              stories = []
              matches = re.findall(
                  r'<script type="application/ld\+json">(.*?)</script>',
                  html,
                  re.DOTALL
              )

              for block in matches:
                  try:
                      data = json.loads(block.strip())
                  except:
                      continue

                  if isinstance(data, dict) and data.get("@type") == "NewsArticle":
                      stories.append({
                          "title": data.get("headline"),
                          "url": data.get("mainEntityOfPage"),
                          "image": data.get("image", [None])[0]
                          if isinstance(data.get("image"), list)
                          else data.get("image")
                      })

              # Deduplicate + limit
              seen = set()
              clean = []
              for s in stories:
                  if s["url"] and s["url"] not in seen:
                      seen.add(s["url"])
                      clean.append(s)

              output["categories"][cat] = clean[:20]

          with open("latest_news.json", "w", encoding="utf-8") as f:
              json.dump(output, f, ensure_ascii=False, indent=2)

          print("Fetched:", {k: len(v) for k, v in output["categories"].items()})
          PY
